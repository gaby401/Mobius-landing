import requests, random, re, time
from bs4 import BeautifulSoup

# ğŸ¯ Leak pattern definitions
PATTERNS = {
    "mnemonic": r"\b(?:\w+\s){11,23}\w+\b",
    "private_key": r"\b0x[a-fA-F0-9]{64}\b",
    "eth_address": r"\b0x[a-fA-F0-9]{40}\b",
    "btc_address": r"\b[13][a-km-zA-HJ-NP-Z1-9]{25,34}\b",
    "jwt": r"\beyJ[a-zA-Z0-9_-]{10,}\.[a-zA-Z0-9._-]+\.[a-zA-Z0-9._-]+\b"
}

# ğŸ§  Leak sources (can be expanded)
TARGETS = [
    "https://controlc.com/",
    "https://justpaste.it/latest",
    "https://rentry.co/latest"
]

# ğŸ›¡ï¸ Get clean proxies from ProxyScrape
def get_proxies():
    url = "https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=3000"
    res = requests.get(url)
    raw = res.text.strip().split("\n")
    proxies = []

    for proxy in raw:
        if re.match(r"^\d{1,3}(\.\d{1,3}){3}:\d{2,5}$", proxy):
            proxies.append(proxy)
    return proxies

# ğŸ“¡ Rotate user agents
def get_headers():
    return {
        "User-Agent": random.choice([
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)",
            "Mozilla/5.0 (X11; Linux x86_64)",
            "Mozilla/5.0 (Linux; Android 10)"
        ])
    }

# ğŸ” Scan a single page with proxy
def scan_url(url, proxy):
    try:
        r = requests.get(url, headers=get_headers(), timeout=10,
                         proxies={"http": proxy, "https": proxy})
        soup = BeautifulSoup(r.text, "html.parser")
        text = soup.get_text()
        findings = {}

        for label, pattern in PATTERNS.items():
            matches = re.findall(pattern, text)
            if matches:
                findings[label] = list(set(matches))
        return findings
    except Exception:
        return {}

def main():
    proxies = get_proxies()
    if not proxies:
        print("âŒ No working proxies found.")
        return

    print(f"ğŸ” Loaded {len(proxies)} proxies.")

    for target in TARGETS:
        proxy = random.choice(proxies)
        print(f"\nğŸ” Scanning {target} using proxy {proxy}...")
        results = scan_url(target, proxy)

        if results:
            print("âš ï¸ Leaks found:")
            for k, v in results.items():
                print(f"  {k.upper()}: {v}")
        else:
            print("âœ… No leak patterns detected.")

        time.sleep(2)

    print("\nâœ… Scan complete.")

if __name__ == "__main__":
    main()
